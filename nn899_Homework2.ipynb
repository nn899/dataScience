{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science\n",
    "## Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Case study\n",
    "- Read [this article](http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html) in the New York Times\n",
    "- Use what we've learned in class as well as from the book and our readings to describe how one could set this up as a predictive modeling problem, such that they could have gotten the results that they did"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Place your answer here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Exploring data in the command line\n",
    "For this part we will be using the data file located in `\"data/advertising_events.csv\"`. This file consists of records that pertain to some advertising events on a given day. There are 4 comma separated columns in this order: `userid`, `timestamp`, `domain`, and `action`. These fields are of type `int`, `int`, `string`, and `int` respectively. Answer the following questions using Linux/Unix bash commands. All questions can be answered in one line (sometimes, with pipes)! Some questions will have many possible solutions. Don't forget that in IPython notebooks you must prefix all bash commands with an exclamation point, i.e. `\"!command arguments\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. How many records are in this file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   10341 data/advertising_events.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l \"data/advertising_events.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. How many unique users are in this file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     732\r\n"
     ]
    }
   ],
   "source": [
    "!cut -d , -f1 data/advertising_events.csv | sort | uniq | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Rank all domains by the number of visits they received in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3114 google.com\r\n",
      "2092 facebook.com\r\n",
      "1036 youtube.com\r\n",
      "1034 yahoo.com\r\n",
      "1022 baidu.com\r\n",
      " 513 wikipedia.org\r\n",
      " 511 amazon.com\r\n",
      " 382 qq.com\r\n",
      " 321 twitter.com\r\n",
      " 316 taobao.com\r\n"
     ]
    }
   ],
   "source": [
    "!cut -d , -f3 data/advertising_events.csv | sort | uniq -c | sort -nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. List all records for the user with user id 37."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37,648061658,google.com,0\r\n",
      "37,642479972,google.com,2\r\n",
      "37,644493341,facebook.com,2\r\n",
      "37,654941318,facebook.com,1\r\n",
      "37,649979874,baidu.com,1\r\n",
      "37,653061949,yahoo.com,1\r\n",
      "37,655020469,google.com,3\r\n",
      "37,640878012,amazon.com,0\r\n",
      "37,659864136,youtube.com,1\r\n",
      "37,640361378,yahoo.com,1\r\n",
      "37,653862134,facebook.com,0\r\n",
      "37,648828970,youtube.com,0\r\n"
     ]
    }
   ],
   "source": [
    "!grep  '^37\\,' data/advertising_events.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Dealing with messy data\n",
    "Not all data you will deal with is going to be clean. In fact, much of it will be very messy! For example, we have the HTML page that lists the contributors to Facebook's [osquery](https://github.com/facebook/osquery) project that is hosted on [Github.com](https://github.com). In this case, all we are interested in are the contributors and how many commits each of them has. Given the HTML page in `\"data/osquery_contributors.html\"` you will sift through tons of irrelevant data so that you can build a useful data structure.\n",
    "\n",
    "Notice that the first six (out of 59 total) contributors are named \"theopolis\", \"marpaia\", \"javuto\", \"jedi22\", \"unixist\", and \"mofarrell\". They have 553, 477, 104, 49, 30, 25 commits respectively.\n",
    "\n",
    "![Screenshot](images/osquery_contributors.png)\n",
    "\n",
    "To get a better of understanding of how this data is stored in the file, try searching through the raw data file for these usernames to look for any patterns. Your final dictionary should have 59 elements!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Turn this data into a Python dictionary called `contributors` where the keys are the contributor names and the values are the number of commits that each contributor has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'shawndavenport': '1', 'jedi22': '49', 'schettino72': '2', 'jamesgpearce': '2', 'marpaia': '477', 'wxsBSD': '20', 'blakefrantz': '6', 'yetanotherhacker': '1', 'lwhsu': '22', 'mimeframe': '3', 'd0ugal': '1', 'maus-': '9', 'kost': '1', 'polachok': '14', 'achmiel': '3', 'vmauge': '8', 'theopolis': '553', 'yannick': '1', 'SimplyAhmazing': '1', 'timzimmermann': '2', 'mark-ignacio': '1', 'mgoffin': '2', 'deniszh': '3', 'Anubisss': '2', 'vlajos': '1', 'dreid': '1', 'astanway': '6', 'arubdesu': '1', 'sharvilshah': '23', 'jreese': '2', 'justintime32': '1', 'nlsun': '3', 'mathieuk': '2', 'ecin': '1', 'blackfist': '1', 'apage43': '1', 'zwass': '14', 'mofarrell': '25', 'maclennann': '6', 'quad': '1', 'arirubinstein': '4', 'brandt': '3', 'rjeczalik': '1', 'ga2arch': '2', 'mtmcgrew': '1', 'alex': '1', 'unixist': '30', 'cdown': '4', 'javuto': '104', 'larzconwell': '1', 'castrapel': '2', 'jacknagz': '1', 'akshaydixi': '5', 'mlw': '2', 'glensc': '2', 'tburgin': '1', 'DavidGosselin': '1', 'eastebry': '9'}\n"
     ]
    }
   ],
   "source": [
    "import re # you might find this package useful\n",
    "\n",
    "contributors = dict()\n",
    "\n",
    "# Place your code here\n",
    "html = open(\"data/osquery_contributors.html\")\n",
    "contents = html.read()\n",
    "#removing all html tags\n",
    "content_without_tags = re.sub(\"<.*?>\", \"\", contents)\n",
    "#removing all the extra whitespaces and newlines\n",
    "text_only = \" \".join(content_without_tags.split())\n",
    "#inserting new line before each user data\n",
    "temp0 = re.sub(\"#\", \"\\n#\", text_only)\n",
    "#discard unnecessary text\n",
    "temp1 = re.sub(\"commit.*\", \"\", temp0)\n",
    "key_values = re.findall(\"#\\d+ +(.*) \\n\", temp1)\n",
    "#inserting in dictionary \n",
    "for i in key_values:\n",
    "    (key, value) = i.split(\" \")\n",
    "    contributors[key] = value\n",
    "# This line will print your dictionary for grading purposed. Do not remove this line!!!\n",
    "print contributors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Dealing with data Pythonically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You might find these packages useful. You may import any other you want!\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Download the data set `\"data/ads_dataset.tsv\"` and load it into a Python Pandas data frame called `ads`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "ads = DataFrame.from_csv('data/ads_dataset.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Write a Python function called `getDfSummary()` that does the following:\n",
    "- Takes as input a data frame\n",
    "- For each variable in the data frame calculates the following features:\n",
    "  - `number_nan` to count the number of missing not-a-number values\n",
    "  - Ignoring missing, NA, and Null values:\n",
    "    - `number_distinct` to count the number of distinct values a variable can take on\n",
    "    - `mean`, `max`, `min`, `std` (standard deviation), and `25%`, `50%`, `75%` to correspond to the appropriate percentiles\n",
    "- All of these new features should be loaded in a new data frame. Each row of the data frame should be a variable from the input data frame, and the columns should be the new summary features.\n",
    "- Returns this new data frame containing all of the summary information\n",
    "\n",
    "Hint: The pandas `describe()` method returns a useful series of values that can be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDfSummary(input_data):\n",
    "    frame = pd.DataFrame(input_data.describe().transpose())\n",
    "    frame['number_nan'] = input_data.isnull().sum()\n",
    "    new_columns = frame.columns.values\n",
    "    new_columns[0] = 'number_distinct'\n",
    "    frame.columns = new_columns\n",
    "    output_data = frame\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. How long does it take for your `getDfSummary()` function to work on your `ads` data frame? Show us the results below.\n",
    "\n",
    "Hint: `%timeit getDfSummary(ads)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 70.8 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit getDfSummary(ads)\n",
    "#10 loops, best of 3: 68.2 ms per loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Using the results returned from `getDfSummary()`, which fields, if any, contain missing `NaN` values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'buy_freq'], dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place your code here\n",
    "getDfSummary(ads).transpose().columns[(getDfSummary(ads).transpose() != 0).all()]\n",
    "# Out[29]: Index([u'buy_freq'], dtype='object')\n",
    "# buy_freq contains NaN values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. For the fields with missing values, does it look like the data is missing at random? Are there any other fields that correlate perfectly, or predict that the data is missing? If missing, what should the data value be?\n",
    "\n",
    "Hint: create another data frame that has just the records with a missing value. Get a summary of this data frame using `getDfSummary()` and compare the differences. Do some feature distributions change dramatically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isbuyer         number_distinct     True\n",
       "                mean                True\n",
       "                std                 True\n",
       "                min                False\n",
       "                25%                False\n",
       "                50%                False\n",
       "                75%                False\n",
       "                max                 True\n",
       "                number_nan         False\n",
       "buy_freq        number_distinct     True\n",
       "                mean                True\n",
       "                std                 True\n",
       "                min                 True\n",
       "                25%                 True\n",
       "                50%                 True\n",
       "                75%                 True\n",
       "                max                 True\n",
       "                number_nan         False\n",
       "visit_freq      number_distinct     True\n",
       "                mean                True\n",
       "                std                 True\n",
       "                min                 True\n",
       "                25%                False\n",
       "                50%                False\n",
       "                75%                False\n",
       "                max                False\n",
       "                number_nan         False\n",
       "buy_interval    number_distinct     True\n",
       "                mean                True\n",
       "                std                 True\n",
       "                                   ...  \n",
       "multiple_visit  75%                False\n",
       "                max                False\n",
       "                number_nan         False\n",
       "uniq_urls       number_distinct     True\n",
       "                mean                True\n",
       "                std                 True\n",
       "                min                False\n",
       "                25%                False\n",
       "                50%                False\n",
       "                75%                False\n",
       "                max                False\n",
       "                number_nan         False\n",
       "num_checkins    number_distinct     True\n",
       "                mean                True\n",
       "                std                 True\n",
       "                min                False\n",
       "                25%                 True\n",
       "                50%                 True\n",
       "                75%                 True\n",
       "                max                False\n",
       "                number_nan         False\n",
       "y_buy           number_distinct     True\n",
       "                mean                True\n",
       "                std                 True\n",
       "                min                False\n",
       "                25%                False\n",
       "                50%                False\n",
       "                75%                False\n",
       "                max                False\n",
       "                number_nan         False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place your code here\n",
    "# create another data frame that has just the records with a missing value\n",
    "df = ads[ads.isnull().any(axis=1)]\n",
    "# Get a summary of this data frame using getDfSummary() \n",
    "df2 = getDfSummary(df)\n",
    "# compare the differences.\n",
    "df1 = getDfSummary(ads)\n",
    "compareDf = (df1 != df2).stack()\n",
    "#looking at these frames, its clear that buy_freq value is missing for a lot of records.\n",
    "# for the records where buy_freq is NaN, isbuyer, multiple_buy, buy_interval and expected_time_buy is also 0. \n",
    "compareDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Which variables are binary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['isbuyer', 'multiple_buy', 'multiple_visit', 'y_buy']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place your code here\n",
    "bool_vars = [col for col in ads\n",
    "if ads[[col]].dropna().isin([0, 1]).all().values]\n",
    "#In [15]: bool_vars\n",
    "#Out[15]: ['isbuyer', 'multiple_buy', 'multiple_visit', 'y_buy']\n",
    "bool_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. Generate a correlation matrix for the `ads` data frame. Is there any redundancy in the data? Are there any features that aren't needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbuyer</th>\n",
       "      <th>buy_freq</th>\n",
       "      <th>visit_freq</th>\n",
       "      <th>buy_interval</th>\n",
       "      <th>sv_interval</th>\n",
       "      <th>expected_time_buy</th>\n",
       "      <th>expected_time_visit</th>\n",
       "      <th>last_buy</th>\n",
       "      <th>last_visit</th>\n",
       "      <th>multiple_buy</th>\n",
       "      <th>multiple_visit</th>\n",
       "      <th>uniq_urls</th>\n",
       "      <th>num_checkins</th>\n",
       "      <th>y_buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>isbuyer</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.326373</td>\n",
       "      <td>0.253749</td>\n",
       "      <td>0.037496</td>\n",
       "      <td>-0.187782</td>\n",
       "      <td>-0.080492</td>\n",
       "      <td>-0.089678</td>\n",
       "      <td>-0.089678</td>\n",
       "      <td>0.379045</td>\n",
       "      <td>0.231174</td>\n",
       "      <td>-0.006641</td>\n",
       "      <td>-0.004424</td>\n",
       "      <td>0.112434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.487548</td>\n",
       "      <td>0.398839</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>-0.291767</td>\n",
       "      <td>0.060817</td>\n",
       "      <td>-0.126793</td>\n",
       "      <td>-0.126793</td>\n",
       "      <td>0.735054</td>\n",
       "      <td>0.154837</td>\n",
       "      <td>0.042624</td>\n",
       "      <td>0.042764</td>\n",
       "      <td>0.128118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>visit_freq</th>\n",
       "      <td>0.326373</td>\n",
       "      <td>0.487548</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.262660</td>\n",
       "      <td>0.140983</td>\n",
       "      <td>-0.147219</td>\n",
       "      <td>-0.121919</td>\n",
       "      <td>-0.171388</td>\n",
       "      <td>-0.171388</td>\n",
       "      <td>0.354157</td>\n",
       "      <td>0.472163</td>\n",
       "      <td>0.039079</td>\n",
       "      <td>0.048881</td>\n",
       "      <td>0.118092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>buy_interval</th>\n",
       "      <td>0.253749</td>\n",
       "      <td>0.398839</td>\n",
       "      <td>0.262660</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042134</td>\n",
       "      <td>0.005762</td>\n",
       "      <td>0.010266</td>\n",
       "      <td>-0.046015</td>\n",
       "      <td>-0.046015</td>\n",
       "      <td>0.669442</td>\n",
       "      <td>0.083427</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>0.008804</td>\n",
       "      <td>0.068453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sv_interval</th>\n",
       "      <td>0.037496</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.140983</td>\n",
       "      <td>0.042134</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.017179</td>\n",
       "      <td>-0.150368</td>\n",
       "      <td>-0.150368</td>\n",
       "      <td>0.022634</td>\n",
       "      <td>0.534310</td>\n",
       "      <td>0.094210</td>\n",
       "      <td>0.073020</td>\n",
       "      <td>0.011096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_buy</th>\n",
       "      <td>-0.187782</td>\n",
       "      <td>-0.291767</td>\n",
       "      <td>-0.147219</td>\n",
       "      <td>0.005762</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.053677</td>\n",
       "      <td>-0.001402</td>\n",
       "      <td>-0.001402</td>\n",
       "      <td>-0.495407</td>\n",
       "      <td>-0.059168</td>\n",
       "      <td>-0.008078</td>\n",
       "      <td>-0.005148</td>\n",
       "      <td>-0.038141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expected_time_visit</th>\n",
       "      <td>-0.080492</td>\n",
       "      <td>0.060817</td>\n",
       "      <td>-0.121919</td>\n",
       "      <td>0.010266</td>\n",
       "      <td>0.017179</td>\n",
       "      <td>0.053677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.284973</td>\n",
       "      <td>-0.284973</td>\n",
       "      <td>-0.013129</td>\n",
       "      <td>-0.516888</td>\n",
       "      <td>-0.083879</td>\n",
       "      <td>-0.051314</td>\n",
       "      <td>0.011826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_buy</th>\n",
       "      <td>-0.089678</td>\n",
       "      <td>-0.126793</td>\n",
       "      <td>-0.171388</td>\n",
       "      <td>-0.046015</td>\n",
       "      <td>-0.150368</td>\n",
       "      <td>-0.001402</td>\n",
       "      <td>-0.284973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.058602</td>\n",
       "      <td>-0.183995</td>\n",
       "      <td>0.268582</td>\n",
       "      <td>0.142725</td>\n",
       "      <td>-0.059171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_visit</th>\n",
       "      <td>-0.089678</td>\n",
       "      <td>-0.126793</td>\n",
       "      <td>-0.171388</td>\n",
       "      <td>-0.046015</td>\n",
       "      <td>-0.150368</td>\n",
       "      <td>-0.001402</td>\n",
       "      <td>-0.284973</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.058602</td>\n",
       "      <td>-0.183995</td>\n",
       "      <td>0.268582</td>\n",
       "      <td>0.142725</td>\n",
       "      <td>-0.059171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_buy</th>\n",
       "      <td>0.379045</td>\n",
       "      <td>0.735054</td>\n",
       "      <td>0.354157</td>\n",
       "      <td>0.669442</td>\n",
       "      <td>0.022634</td>\n",
       "      <td>-0.495407</td>\n",
       "      <td>-0.013129</td>\n",
       "      <td>-0.058602</td>\n",
       "      <td>-0.058602</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.123419</td>\n",
       "      <td>0.004246</td>\n",
       "      <td>0.005247</td>\n",
       "      <td>0.109926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multiple_visit</th>\n",
       "      <td>0.231174</td>\n",
       "      <td>0.154837</td>\n",
       "      <td>0.472163</td>\n",
       "      <td>0.083427</td>\n",
       "      <td>0.534310</td>\n",
       "      <td>-0.059168</td>\n",
       "      <td>-0.516888</td>\n",
       "      <td>-0.183995</td>\n",
       "      <td>-0.183995</td>\n",
       "      <td>0.123419</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>0.045599</td>\n",
       "      <td>0.070968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniq_urls</th>\n",
       "      <td>-0.006641</td>\n",
       "      <td>0.042624</td>\n",
       "      <td>0.039079</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>0.094210</td>\n",
       "      <td>-0.008078</td>\n",
       "      <td>-0.083879</td>\n",
       "      <td>0.268582</td>\n",
       "      <td>0.268582</td>\n",
       "      <td>0.004246</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.419581</td>\n",
       "      <td>-0.019238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_checkins</th>\n",
       "      <td>-0.004424</td>\n",
       "      <td>0.042764</td>\n",
       "      <td>0.048881</td>\n",
       "      <td>0.008804</td>\n",
       "      <td>0.073020</td>\n",
       "      <td>-0.005148</td>\n",
       "      <td>-0.051314</td>\n",
       "      <td>0.142725</td>\n",
       "      <td>0.142725</td>\n",
       "      <td>0.005247</td>\n",
       "      <td>0.045599</td>\n",
       "      <td>0.419581</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y_buy</th>\n",
       "      <td>0.112434</td>\n",
       "      <td>0.128118</td>\n",
       "      <td>0.118092</td>\n",
       "      <td>0.068453</td>\n",
       "      <td>0.011096</td>\n",
       "      <td>-0.038141</td>\n",
       "      <td>0.011826</td>\n",
       "      <td>-0.059171</td>\n",
       "      <td>-0.059171</td>\n",
       "      <td>0.109926</td>\n",
       "      <td>0.070968</td>\n",
       "      <td>-0.019238</td>\n",
       "      <td>-0.007766</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      isbuyer  buy_freq  visit_freq  buy_interval  \\\n",
       "isbuyer              1.000000       NaN    0.326373      0.253749   \n",
       "buy_freq                  NaN  1.000000    0.487548      0.398839   \n",
       "visit_freq           0.326373  0.487548    1.000000      0.262660   \n",
       "buy_interval         0.253749  0.398839    0.262660      1.000000   \n",
       "sv_interval          0.037496  0.000280    0.140983      0.042134   \n",
       "expected_time_buy   -0.187782 -0.291767   -0.147219      0.005762   \n",
       "expected_time_visit -0.080492  0.060817   -0.121919      0.010266   \n",
       "last_buy            -0.089678 -0.126793   -0.171388     -0.046015   \n",
       "last_visit          -0.089678 -0.126793   -0.171388     -0.046015   \n",
       "multiple_buy         0.379045  0.735054    0.354157      0.669442   \n",
       "multiple_visit       0.231174  0.154837    0.472163      0.083427   \n",
       "uniq_urls           -0.006641  0.042624    0.039079      0.013895   \n",
       "num_checkins        -0.004424  0.042764    0.048881      0.008804   \n",
       "y_buy                0.112434  0.128118    0.118092      0.068453   \n",
       "\n",
       "                     sv_interval  expected_time_buy  expected_time_visit  \\\n",
       "isbuyer                 0.037496          -0.187782            -0.080492   \n",
       "buy_freq                0.000280          -0.291767             0.060817   \n",
       "visit_freq              0.140983          -0.147219            -0.121919   \n",
       "buy_interval            0.042134           0.005762             0.010266   \n",
       "sv_interval             1.000000           0.001817             0.017179   \n",
       "expected_time_buy       0.001817           1.000000             0.053677   \n",
       "expected_time_visit     0.017179           0.053677             1.000000   \n",
       "last_buy               -0.150368          -0.001402            -0.284973   \n",
       "last_visit             -0.150368          -0.001402            -0.284973   \n",
       "multiple_buy            0.022634          -0.495407            -0.013129   \n",
       "multiple_visit          0.534310          -0.059168            -0.516888   \n",
       "uniq_urls               0.094210          -0.008078            -0.083879   \n",
       "num_checkins            0.073020          -0.005148            -0.051314   \n",
       "y_buy                   0.011096          -0.038141             0.011826   \n",
       "\n",
       "                     last_buy  last_visit  multiple_buy  multiple_visit  \\\n",
       "isbuyer             -0.089678   -0.089678      0.379045        0.231174   \n",
       "buy_freq            -0.126793   -0.126793      0.735054        0.154837   \n",
       "visit_freq          -0.171388   -0.171388      0.354157        0.472163   \n",
       "buy_interval        -0.046015   -0.046015      0.669442        0.083427   \n",
       "sv_interval         -0.150368   -0.150368      0.022634        0.534310   \n",
       "expected_time_buy   -0.001402   -0.001402     -0.495407       -0.059168   \n",
       "expected_time_visit -0.284973   -0.284973     -0.013129       -0.516888   \n",
       "last_buy             1.000000    1.000000     -0.058602       -0.183995   \n",
       "last_visit           1.000000    1.000000     -0.058602       -0.183995   \n",
       "multiple_buy        -0.058602   -0.058602      1.000000        0.123419   \n",
       "multiple_visit      -0.183995   -0.183995      0.123419        1.000000   \n",
       "uniq_urls            0.268582    0.268582      0.004246        0.043860   \n",
       "num_checkins         0.142725    0.142725      0.005247        0.045599   \n",
       "y_buy               -0.059171   -0.059171      0.109926        0.070968   \n",
       "\n",
       "                     uniq_urls  num_checkins     y_buy  \n",
       "isbuyer              -0.006641     -0.004424  0.112434  \n",
       "buy_freq              0.042624      0.042764  0.128118  \n",
       "visit_freq            0.039079      0.048881  0.118092  \n",
       "buy_interval          0.013895      0.008804  0.068453  \n",
       "sv_interval           0.094210      0.073020  0.011096  \n",
       "expected_time_buy    -0.008078     -0.005148 -0.038141  \n",
       "expected_time_visit  -0.083879     -0.051314  0.011826  \n",
       "last_buy              0.268582      0.142725 -0.059171  \n",
       "last_visit            0.268582      0.142725 -0.059171  \n",
       "multiple_buy          0.004246      0.005247  0.109926  \n",
       "multiple_visit        0.043860      0.045599  0.070968  \n",
       "uniq_urls             1.000000      0.419581 -0.019238  \n",
       "num_checkins          0.419581      1.000000 -0.007766  \n",
       "y_buy                -0.019238     -0.007766  1.000000  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place your code here\n",
    "CorrelFrame = ads.corr()\n",
    "#last_buy and last_visit fields are perfectly co-related. One of these features can be discarded.\n",
    "CorrelFrame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
